# 
# THIS DOCUMENTATION IS A PREVIEW.  DDM DOES NOT YET WORK LIKE THIS.
#

1) Introduction

DDM is a simple tool that helps you manage your data, distributed over multiple
(*nix) systems.  It must be seen in a bigger context of file organisation,
meta-data, version control and backup strategies.
The main point is that different sets of data can have different requirements.

You probably have multiple sets of data (e.g.: music, images, documents, movies,
sofware projects, ...) that you use/store on more then one system for a variety of reasons
(backups, centralized management, having access to your data from several
places, collaboration, ...).  You probably also have specific 'rules' on how you use these
sets of data on your systems.
Some examples:
* You have a series of TV episodes on your fileserver and you want the latest 5 that you haven't watched yet available on your laptop.
* You have a giant music collection on your fileserver.  You want your favorite music (based on statistics from your media player) available on your laptop. 
  Also, sometimes you rip (your own) cd's which must be properly tagged first and then added to your collection and stored on your mobile media player.
* After capturing new images with a digital camera you put them on your laptop first but you like to sync them to your file server frequently. 
  You don't need all the high-res images stored on your laptop.  They consume too much space, and you think syncing them to your server is a great backup.
  On the other hand you also want *some* of your high-res images (stored on the server) available for editing on the
  laptop, separating edited images from their originals through whatever medium seems most appropriate (version control, separate directories, or a
  feature of your image editor)
  You might have the same images in a smaller format on your server (for gallery programs etc.) and want these (or a select few albums of them) available on the road
  also, clearly separated from the high-res ones of course.

If you starting thinking about it, you probably realize that you have some similar examples yourself. 
And maybe you'll even notice that your current way of managing everything could be improved.

You can try managing everything by hand using rsync/(s)cp/svn/git/... but it limits
your ability to actually use your data the way you want it.  
The more different types of data you have and the more you (want to) have specific
work flows the harder it becomes to keep your data up to date, consistent
and organized in a flexible way on your boxes.  Especially a home directory can become a mess if not tightly managed
and controlled.

This is where DDM comes in.
It's goal is to let you come up with specific work flows and usage patterns for your data.
You tell ddm what tools to use ( rsync/(s)cp/svn/git/rm/... ) and how to use them, making managing your data much more peaceful and
powerfull.  DDM is the Distributed Data Manager.


2) Disclaimer

The code is far from finished. Some features are still missing and there will be bugs in it.
Even the concepts themselves are still in evolution.
Don't blame the author if ddm deletes the wrong files or causes your computer to blow up.


3) Concepts

These are the basic concepts.  They will be explained in the following chapters.

 * repositories: A DDM repository is like a version control repository but in a broader sense.
   - repo tye: A repository has a specific type. (eg. 'svn' or 'vfs')
   - repo name: The name of the repository (eg. 'pictures')
 * datasets: this is a directory on a system that corresponds to some repository.
   - dataset name: The name of a dataset. (eg. 'pictures')
   - dataset type: How the dataset relates to it's corresponding repository. ( eg. 'selection')
 * actions: what to do with a dataset? (eg 'update')
    * action: commit, update, checkout


4) Repositories

A repository is a data store (on your 'server') 
It must have the 'perfect layout' and contain your files just the way you want them (eg songs properly tagged, files tightly organized etc)
They must be kept clean.  If you are 'working' in them, you're doing it wrong.
 * repo type: The type of the repository. Currently there are 2 supported repository types:
   - svn: a normal subversion repository
   - vfs: a directory somewhere in the vfs hierarchy.  Any position in your VFS will do, and how it gets there is entirely up to you.
     (mounted directly, mounted nfs export, sshfs, autoFS, ... )  
 * repo name: A clear, no-nonsense, and preferably unique (in your 'world'. eg over all your ddm repositories) name


5) Datasets

This is a directory on a system that is related in some way to a repository.
This goes way beyond what a "working copy" in VCS lingo is to a repository.
 * dataset name: the name of the dataset (directory) on your system.
   In theory this can be anything you want, but the recommended method is
   using the repository name and suffixing it with a hyphen and the dataset
   type. (eg 'pictures-selection')
 * dataset type: a dataset's type specifies how the dataset relates to it's
   repository.
   Note that not all datasets are defined for all repository types (eg direct for svn repository)
   Dataset types cannot be added by the user, you can however request it and provide a use case to
   defend it.
   - blob: data that is binary and/or hard to grasp for humans, doesn't need tight, fine-grained version control
     and has enough with snapshots at specific points in time of the whole dataset.
     The goal in the future is to make snapshots on points in time,
     but for now a simple rsync should to suffice.
     (for now the implementation is similar to a copy dataset but this will change)
     The main goal for this is usually just backups.  (eg mysql database)  
   - buffer: staging area for a specific kind of data.  It's a temporary storage
     with the only goal of keeping your data until you flush it to the repository.
     (eg: new images)
   - cache: contains tempory data that you don't want in any repository. 
     This dataset is supposed to be maintained by programs, not by users. 
     If you feel like using a cache dataset manually, just go for the extension (and
     don't back it up)
   - copy: a copy of all content in the repo (an svn working copy or a directory using rsync)
   - direct: a (symlink to a) path on a remote location. (usually an nfs mount or subdirectory thereof)
     useful for quick access to big collections when physically possible.
   - extension: contains unique content that you don't want in your
     corresponding repository. This content will never be pushed to the corresponding repository (so the only
     'relation' to the corresponding repository is the name/type of media, not the data itself).
     However, for backup purposes, this content *can* be backed up to a
     repository with the suffix '-extension'.  So this dataset type can also
     be considered a copy dataset for the repository 'foo-extension' where 'foo' can be freely
     choosen. 
   - selection: a copy of a subset of the data in the repo
     (eg: your favourite movies of all your movies)
 * configuration: any (optional) configuration settings or custom actions can be specified in a file '.ddm' in the dataset.
   This file will be sourced by bash.
   This is not needed and sometimes even not possible (eg direct dataset for an unmounted filesystem)  
   These are the variables that can be specified, along with their default configuration:
     DATASET_LOCAL='' #path to dataset locally (including type suffix if any)
     DATASET_REMOTE='' #path to dataset remotely (or locally if network mount)
     DATASET_PATH='' #just the path (until parent directory of dataset)
     DATASET_DIR_NAME='' #like $DATASET_LOCAL but no path
     DATASET_DIR_NAME_REL # identifier to dataset, taken against pwd (could be '.','..', nothing at all, dirname, full path, ..)
     DATASET_NAME='' #like $DATASET_DIR_NAME but no type suffix
     DATASET_TYPE=''
     REPOSITORY_TYPE=''
   You can also override the following callbacks:
     pre{checkout,commit,update,flush,backup,restore}
     do{checkout,commit,update,flush,backup,restore}
     post{checkout,commit,update,flush,backup,restore}
   And you can create custom ones, eg:
     do$foo
     post$foo

If no dataset type can be found in the configuration or parsed from the dataset name,
then the dataset will be assumed to be of the type 'copy' by default.


6) Actions

The action specifies an operation to be performed on a dataset.  Usually the
action interacts with the corresponding repository, but this does not always
need to be the case.  You can inject whatever commands in actions.  (this
can be useful for example for the update action on a buffer)
Some action names are bound to a specific dataset type, but you can create your own
actions, override and even unset defaults.
Not all actions have to be defined for all dataset types.

These are the default actions and to which corresponding repositories they apply by default:
(Note, these are all possible dataset types: blob, buffer, cache, copy, direct, extension, selection)
 * backup:   backs up the state of the dataset (alias for commit for all datasets, also works for extensions )
 * checkout: set up the dataset ( blob, copy, direct/vfs*, selection)
 * commit:   commit the state/changes of the dataset to the repository (blob, buffer/vfs (alias for flush by default), copy)
 * flush:    empty dataset and forward to repository if applicable ( buffer, cache )
 * restore:  restore the state of the dataset (alias for update for all datasets)
 * update:   update the files in the dataset ( selection, copy, blob, direct*)

(*) : not implemented yet.  will basically just mount the corresponding filesystem

You can create your own actions in .ddm files or plugins if you would find that
necessary.  Just create callback functions like {pre,do,post}<custom action name>.
Not all 3 are needed.
You can also disable callbacks or actions (disabling all 3 callbacks) if you would find that necessary. To do it, you
just need to unset the functions in .ddm files or plugins. (unset -f <callback>)
Note:
 * You can call another callback, but don't call it directly. call it as 'do_callback <callback>'
   (This wrapper make sure the callback exists, among others)
 * If you add,disable,.. actions, you must update ALLOWED_ACTIONS, you can
   do this by overriding it in your ddmrc. 

Note that the ddm command-line tool performs the above described actions on datasets.
These actions generally either manipulate or create datasets, or update
repositories.  Deleting datasets and setting up/managing/deleting repositories are to be done manually.


7) Global configuration

 Global configuration is done in the file ddmrc, which is to be placed in a 'ddm' subdirectory of the appropriate XDG basedir.
 By default this means $HOME/.config/ddm/ddmrc ( see http://standards.freedesktop.org/basedir-spec/basedir-spec-0.6.html )
 These are the variables that can be specified, along with their default configuration:
   DEBUG='' #set to 1 for debugging
   SVN_BASE=''
   SVN_PREFIX=''
   SVN_SUFFIX=''
   VFS_BASE=''
   VFS_PREFIX=''
   VFS_SUFFIX=''
   ALLOWED_REPOSITORY_TYPES='svn vfs'
   DEFAULT_REPOSITORY_TYPE='vfs'
   IGNORE_DATASET_REMOTE_SVN=0 #nag if the repo url figured out is not the same as the one in 'svn info'. you should leave this 0
   ALLOWED_DATASET_TYPES='blob buffer cache copy direct extension selection'
   ALLOWED_ACTIONS='backup checkout commit flush restore update'

 Unless overridden, ddm will construct the repo path as follows: $TYPE_BASE/$TYPE_PREFIX$DATASET_NAME$TYPE_SUFFIX


8) Invocation

 See ddm -h


9) Exit codes

 0 All OK
 1 Something wrong with ddmrc
 2 Something wrong with dataset
 3 Something wrong with repository
 4 Something wrong with action
 5 Something wrong while parsing arguments
 100 Internal problem / undefined exitcode


10) Internals

  10.1) Functions

   * actions.    specified on command-line. (eg update)
   * callbacks.  executed by ddm based on action.  Can be overridden with .ddm files. (eg {pre,do,post}update)
   * workers.    called by callbacks or other workers.  Can be overridden/extended with plugins. (eg no_action, wrap_rsync, getfiles, delefiles, keepfiles, ...)
     - wrappers.   special kind of worker functions for a specific purpose (eg wrap_rsync, wrap_keep). pretend-mode switching happens here.
     - non-wrappers (eg getfiles, deletefiles) call wrappers for 'dangerous' things, so non-wrappers don't need to implement any pretend-mode checking
  
  10.2) Notes
 
  * All functions except wrappers expect relative paths, where the root is the dataset/repository directory.
    Wrappers are very specific, they require absolute paths.

11) Examples

  9.1) Example ddmrc

  This is a pretty default config, with an svn repository reachable through https
  where all ddm repositories start with 'ddm-', and a vfs repository
  reachable through autofs, where all ddm repositories are in the 'ddm-repo' directory
    ALLOWED_REPOSITORY_TYPES='svn vfs'
    DEFAULT_REPOSITORY_TYPE='vfs'
    SVN_BASE='https://server/svn/repos/'
    SVN_PREFIX='ddm-'
    VFS_BASE='/net/server/home/dieter/ddm-repo'

  9.2) Updating a selection of videos

  Suppose you want to have a selection of videos that contains 10 episodes that you still need to watch,
  keeping the last one you watched, and discarding all others.

  The easiest way is to name the dataset video-selection, and put this .ddm in it:
    doupdate()
    {
       slidewindow mplayer 10 1
    }

  Then you can just invoke ddm like this:
    dieter@dieter-mbp:~$ ddm -a update -d video-selection -v
    Included /home/dieter/video-selection/.ddm
    action update on dataset name video type selection
    Deleting old files... (3 items).
     * /home/dieter/video-selection/910 - The One With Christmas In Tulsa.avi... success
     * /home/dieter/video-selection/911 - The One Where Rachel Goes Back To Work.avi... success
     * /home/dieter/video-selection/912 - The One With Phoebes Rats.avi... success
    Keeping these files... (1 items).
     * /home/dieter/video-selection/913 - The One Where Monica Sings.avi
    Copying new files... (10 items).
     * /home/dieter/video-selection/914 - The One With The Blind Dates.avi... success
     * /home/dieter/video-selection/915 - The One With the Mugging.avi... success
     * /home/dieter/video-selection/916 - The One With The Boob Job.avi... success
     * /home/dieter/video-selection/917 - The One With The Memorial Service.avi... success
     * /home/dieter/video-selection/918 - The One With The Lottery.avi... success
     * /home/dieter/video-selection/919 - The One With Rachels Dream.avi... success
     * /home/dieter/video-selection/920 - The One With The Soap Opera Party.avi... success
     * /home/dieter/video-selection/921 - The One With The Fertility Test.avi... success
     * /home/dieter/video-selection/922 - The One With The Donor.avi... success
     * /home/dieter/video-selection/923 - 924 - The One In Barbados.avi... success
    finished
